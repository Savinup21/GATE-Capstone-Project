{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.utils import to_categorical, Sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.set_option('display.max_colwidth', None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "full_training = []\n",
        "\n",
        "paths = [\n",
        "    ('C:/Users/savin/Downloads/FracAtlas/FracAtlas/images/Fractured', 0),\n",
        "    ('C:/Users/savin/Downloads/FracAtlas/FracAtlas/images/Non_fractured', 1)\n",
        "]\n",
        "\n",
        "for folder, label in paths:\n",
        "    for x in os.listdir(folder):\n",
        "        if x.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            full_training.append({'Image_path': os.path.join(folder, x), 'Classification': label})\n",
        "\n",
        "mura_csv = pd.read_csv('C:/Users/savin/Downloads/MURA-v1.1/train_image_paths.csv')\n",
        "base_dir = 'C:/Users/savin/Downloads/'\n",
        "for x in mura_csv.iloc[:, 0]:\n",
        "    label = 0 if 'positive' in x else 1 if 'negative' in x else None\n",
        "    if label is not None:\n",
        "        full_training.append({'Image_path': os.path.join(base_dir, x), 'Classification': label})\n",
        "\n",
        "extra_paths = [\n",
        "    ('C:/Users/savin/Downloads/data/data/train/b', 0),\n",
        "    ('C:/Users/savin/Downloads/data/data/train/nb', 1),\n",
        "    ('C:/Users/savin/Downloads/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/train/fractured', 0),\n",
        "    ('C:/Users/savin/Downloads/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/train/not fractured', 1)\n",
        "\n",
        "]\n",
        "\n",
        "for folder, label in extra_paths:\n",
        "    for x in os.listdir(folder):\n",
        "        if x.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            full_training.append({'Image_path': os.path.join(folder, x), 'Classification': label})\n",
        "\n",
        "\n",
        "full_training = pd.DataFrame(full_training)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "IMG_SIZE = (128, 128)\n",
        "images, labels = [], []\n",
        "\n",
        "for _, row in full_training.iterrows():\n",
        "    img = load_img(row['Image_path'], target_size=IMG_SIZE)\n",
        "    img_array = img_to_array(img) / 255.0\n",
        "    images.append(img_array)\n",
        "\n",
        "    labels.append(int(row['Classification']))\n",
        "\n",
        "images = np.array(images, dtype=\"float32\")\n",
        "labels = np.array(labels, dtype=\"int\")\n",
        "\n",
        "labels_categorical = to_categorical(labels, num_classes=2)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    images, labels_categorical, test_size=0.2, stratify=labels, random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NumpyDataGenerator(Sequence):\n",
        "    def __init__(self, images, labels, batch_size=64, shuffle=True):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.indices = np.arange(len(images))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.images) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        \n",
        "        return self.images[batch_indices], self.labels[batch_indices]\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    MaxPooling2D((2,2)),\n",
        "    Conv2D(64, (3,3), activation='relu', name=\"target_conv_layer\"),\n",
        "    MaxPooling2D((2,2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "train_gen = NumpyDataGenerator(X_train, y_train, batch_size=64)\n",
        "val_gen = NumpyDataGenerator(X_val, y_val, batch_size=64)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "770/770 [==============================] - 12s 13ms/step - loss: 0.6001 - accuracy: 0.6640 - val_loss: 0.5387 - val_accuracy: 0.7109\n",
            "Epoch 2/25\n",
            "770/770 [==============================] - 10s 13ms/step - loss: 0.4905 - accuracy: 0.7427 - val_loss: 0.4944 - val_accuracy: 0.7357\n",
            "Epoch 3/25\n",
            "770/770 [==============================] - 9s 11ms/step - loss: 0.3864 - accuracy: 0.8111 - val_loss: 0.5023 - val_accuracy: 0.7531\n",
            "Epoch 4/25\n",
            "770/770 [==============================] - 9s 11ms/step - loss: 0.2620 - accuracy: 0.8824 - val_loss: 0.6239 - val_accuracy: 0.7386\n",
            "Epoch 5/25\n",
            "770/770 [==============================] - 9s 11ms/step - loss: 0.1542 - accuracy: 0.9368 - val_loss: 0.7781 - val_accuracy: 0.7470\n",
            "Epoch 6/25\n",
            "770/770 [==============================] - 9s 11ms/step - loss: 0.0874 - accuracy: 0.9677 - val_loss: 1.0455 - val_accuracy: 0.7454\n",
            "Epoch 7/25\n",
            "770/770 [==============================] - 9s 11ms/step - loss: 0.0574 - accuracy: 0.9814 - val_loss: 1.2577 - val_accuracy: 0.7461\n",
            "Epoch 8/25\n",
            "770/770 [==============================] - 9s 11ms/step - loss: 0.0414 - accuracy: 0.9869 - val_loss: 1.3807 - val_accuracy: 0.7439\n",
            "Epoch 9/25\n",
            "770/770 [==============================] - 9s 11ms/step - loss: 0.0353 - accuracy: 0.9904 - val_loss: 1.5412 - val_accuracy: 0.7465\n",
            "Epoch 10/25\n",
            "770/770 [==============================] - 9s 11ms/step - loss: 0.0277 - accuracy: 0.9927 - val_loss: 1.4724 - val_accuracy: 0.7438\n",
            "Epoch 11/25\n",
            "770/770 [==============================] - 9s 11ms/step - loss: 0.0294 - accuracy: 0.9924 - val_loss: 1.6888 - val_accuracy: 0.7348\n",
            "Epoch 12/25\n",
            "770/770 [==============================] - 9s 11ms/step - loss: 0.0223 - accuracy: 0.9944 - val_loss: 1.7976 - val_accuracy: 0.7397\n",
            "Epoch 13/25\n",
            "770/770 [==============================] - 9s 11ms/step - loss: 0.0168 - accuracy: 0.9956 - val_loss: 2.1013 - val_accuracy: 0.7387\n",
            "Epoch 14/25\n",
            "770/770 [==============================] - 9s 12ms/step - loss: 0.0210 - accuracy: 0.9945 - val_loss: 1.8366 - val_accuracy: 0.7466\n",
            "Epoch 15/25\n",
            "770/770 [==============================] - 9s 11ms/step - loss: 0.0093 - accuracy: 0.9975 - val_loss: 2.0957 - val_accuracy: 0.7407\n",
            "Epoch 16/25\n",
            "770/770 [==============================] - 9s 11ms/step - loss: 0.0168 - accuracy: 0.9952 - val_loss: 2.4461 - val_accuracy: 0.7220\n",
            "Epoch 17/25\n",
            "770/770 [==============================] - 9s 11ms/step - loss: 0.0156 - accuracy: 0.9961 - val_loss: 2.0586 - val_accuracy: 0.7347\n",
            "Epoch 18/25\n",
            "770/770 [==============================] - 9s 11ms/step - loss: 0.0176 - accuracy: 0.9952 - val_loss: 2.0881 - val_accuracy: 0.7336\n",
            "Epoch 19/25\n",
            "770/770 [==============================] - 9s 11ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 2.2348 - val_accuracy: 0.7451\n",
            "Epoch 20/25\n",
            "770/770 [==============================] - 9s 11ms/step - loss: 0.0175 - accuracy: 0.9953 - val_loss: 2.0725 - val_accuracy: 0.7347\n",
            "Epoch 21/25\n",
            "770/770 [==============================] - 9s 12ms/step - loss: 0.0137 - accuracy: 0.9967 - val_loss: 2.2111 - val_accuracy: 0.7419\n",
            "Epoch 22/25\n",
            "770/770 [==============================] - 9s 12ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 2.2949 - val_accuracy: 0.7418\n",
            "Epoch 23/25\n",
            "770/770 [==============================] - 9s 11ms/step - loss: 0.0110 - accuracy: 0.9971 - val_loss: 2.3256 - val_accuracy: 0.7412\n",
            "Epoch 24/25\n",
            "770/770 [==============================] - 9s 12ms/step - loss: 0.0101 - accuracy: 0.9973 - val_loss: 2.2725 - val_accuracy: 0.7290\n",
            "Epoch 25/25\n",
            "770/770 [==============================] - 9s 11ms/step - loss: 0.0104 - accuracy: 0.9973 - val_loss: 2.4962 - val_accuracy: 0.7347\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x20ee6d5ff40>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(train_gen, epochs=25, validation_data=val_gen)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 121ms/step\n",
            "Prediction: Fracture Detected\n"
          ]
        }
      ],
      "source": [
        "img_path = 'C:/Users/savin/GATE Project/download.jpg'\n",
        "image = load_img(img_path, target_size=IMG_SIZE)\n",
        "image_array = img_to_array(image) / 255.0\n",
        "image_array = np.expand_dims(image_array, axis=0)\n",
        "\n",
        "output = model.predict(image_array)\n",
        "predicted_class_index = np.argmax(output)\n",
        "class_labels = ['Fracture Detected', 'No Fracture was Detected']\n",
        "print(\"Prediction:\", class_labels[predicted_class_index])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m     heatmap \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmaximum(heatmap, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m/\u001b[39m tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mreduce_max(heatmap)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m heatmap\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m---> 18\u001b[0m heatmap \u001b[38;5;241m=\u001b[39m get_grad_cam(\u001b[43mmodel\u001b[49m, image_array, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_conv_layer\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m heatmap_resized \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(heatmap, (\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m))\n\u001b[0;32m     20\u001b[0m heatmap_colored \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mapplyColorMap(np\u001b[38;5;241m.\u001b[39muint8(\u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m heatmap_resized), cv2\u001b[38;5;241m.\u001b[39mCOLORMAP_JET)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "def get_grad_cam(model, image, layer_name):\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], \n",
        "        [model.get_layer(layer_name).output, model.output]\n",
        "    )\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(image)\n",
        "        class_idx = tf.argmax(predictions[0])\n",
        "        loss = predictions[:, class_idx]\n",
        "\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
        "    heatmap = np.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "heatmap = get_grad_cam(model, image_array, 'target_conv_layer')\n",
        "heatmap_resized = cv2.resize(heatmap, (128, 128))\n",
        "heatmap_colored = cv2.applyColorMap(np.uint8(255 * heatmap_resized), cv2.COLORMAP_JET)\n",
        "\n",
        "original = cv2.imread(img_path)\n",
        "original = cv2.resize(original, (128, 128))\n",
        "superimposed = cv2.addWeighted(original, 0.6, heatmap_colored, 0.4, 0)\n",
        "\n",
        "plt.imshow(cv2.cvtColor(superimposed, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "plt.title(\"Grad-CAM Highlight\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('my_model1.keras')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
